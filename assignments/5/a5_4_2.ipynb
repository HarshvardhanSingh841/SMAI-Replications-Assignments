{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNqerCGZJo2y",
    "outputId": "6197439d-557a-4d06-8de3-d30b05b062f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generation complete. Images saved to ocr_dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import nltk\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Ensure nltk resources are available\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "\n",
    "# Parameters\n",
    "output_dir = \"ocr_dataset\"\n",
    "image_size = (256, 64)\n",
    "font_size = 32\n",
    "num_samples = 100000\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Fetch word list and sample 100k words\n",
    "word_list = words.words()\n",
    "selected_words = random.sample(word_list, num_samples)\n",
    "\n",
    "# Load a default font\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "# Generate images\n",
    "for word in selected_words:\n",
    "    # Sanitize word to ensure valid filenames\n",
    "    sanitized_word = word.replace(\"/\", \"\").replace(\"\\\\\", \"\")\n",
    "\n",
    "    # Create a blank image with white background\n",
    "    img = Image.new(\"RGB\", image_size, \"white\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Get text size and position\n",
    "    text_bbox = draw.textbbox((0, 0), sanitized_word, font=font)  # Bounding box for the text\n",
    "    text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n",
    "    position = ((image_size[0] - text_width) // 2, (image_size[1] - text_height) // 2)\n",
    "\n",
    "    # Render word onto image\n",
    "    draw.text(position, sanitized_word, fill=\"black\", font=font)\n",
    "\n",
    "    # Save image\n",
    "    filename = f\"{sanitized_word}.png\"\n",
    "    img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "print(f\"Dataset generation complete. Images saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0h3A05pCJufU",
    "outputId": "bd66990b-f589-485c-f5c9-1a27fbfeb9a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 99846\n",
      "Training files: 79876\n",
      "Validation files: 9985\n",
      "Test files: 9985\n",
      "\n",
      "Sample of training files: ['A.png', 'Aani.png', 'Aaronical.png', 'Aaronite.png', 'Aaru.png']\n",
      "Sample of validation files: ['Abadite.png', 'Abassin.png', 'Abrus.png', 'Absi.png', 'Abuta.png']\n",
      "Sample of test files: ['Ababdeh.png', 'Abelicea.png', 'Abipon.png', 'Acanthodidae.png', 'Aceraceae.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Paths\n",
    "ocr_dataset_dir = \"ocr_dataset\"\n",
    "train_dir = os.path.join(ocr_dataset_dir, \"train\")\n",
    "val_dir = os.path.join(ocr_dataset_dir, \"val\")\n",
    "test_dir = os.path.join(ocr_dataset_dir, \"test\")\n",
    "\n",
    "# Clean existing split directories if they exist\n",
    "for dir_path in [train_dir, val_dir, test_dir]:\n",
    "    if os.path.exists(dir_path):\n",
    "        shutil.rmtree(dir_path)\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "# Get list of all image files\n",
    "image_filenames = [f for f in os.listdir(ocr_dataset_dir) if f.endswith(\".png\")]\n",
    "\n",
    "# Shuffle the filenames randomly\n",
    "random.shuffle(image_filenames)\n",
    "\n",
    "# Calculate split indices\n",
    "total_files = len(image_filenames)\n",
    "train_split = int(0.8 * total_files)\n",
    "val_split = int(0.9 * total_files)\n",
    "\n",
    "# Split files\n",
    "train_files = image_filenames[:train_split]\n",
    "val_files = image_filenames[train_split:val_split]\n",
    "test_files = image_filenames[val_split:]\n",
    "\n",
    "# Move files to respective folders\n",
    "for files, dest_dir in zip([train_files, val_files, test_files], [train_dir, val_dir, test_dir]):\n",
    "    for file in files:\n",
    "        src_path = os.path.join(ocr_dataset_dir, file)\n",
    "        if os.path.exists(src_path):  # Check if file exists before moving\n",
    "            shutil.copy2(src_path, os.path.join(dest_dir, file))  # Using copy2 instead of move\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Total files: {total_files}\")\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Validation files: {len(val_files)}\")\n",
    "print(f\"Test files: {len(test_files)}\")\n",
    "\n",
    "# Print sample of files in each split to verify distribution\n",
    "print(\"\\nSample of training files:\", sorted(os.listdir(train_dir))[:5])\n",
    "print(\"Sample of validation files:\", sorted(os.listdir(val_dir))[:5])\n",
    "print(\"Sample of test files:\", sorted(os.listdir(test_dir))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "16mCdEqrSgDw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Dif9ej-WKrDm"
   },
   "outputs": [],
   "source": [
    "class OCRDataset(Dataset):\n",
    "    def __init__(self, image_dir, char_to_idx, transform=None, max_length=30):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(\".png\")]\n",
    "        self.char_to_idx = char_to_idx\n",
    "        self.transform = transform\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_files[idx]\n",
    "        # Extract label from filename (remove .png extension)\n",
    "        label = os.path.splitext(image_name)[0]\n",
    "\n",
    "        # Encode the label using char_to_idx\n",
    "        label_encoded = [self.char_to_idx[char] for char in label]\n",
    "\n",
    "        # Load image\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert label to tensor with padding\n",
    "        label_tensor = torch.full((self.max_length,), -1, dtype=torch.long)  # Fill with padding token (-1)\n",
    "        label_tensor[:len(label_encoded)] = torch.tensor(label_encoded)\n",
    "\n",
    "        return image, label_tensor\n",
    "\n",
    "# Complete character set including upper and lowercase letters, numbers, and common special characters\n",
    "char_set = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 '-\"\n",
    "char_to_idx = {char: idx for idx, char in enumerate(char_set)}\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "LKa9vp_pKxJC"
   },
   "outputs": [],
   "source": [
    "# Create datasets with transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = OCRDataset(\"ocr_dataset/train\", char_to_idx, transform=transform, max_length=30)\n",
    "val_dataset = OCRDataset(\"ocr_dataset/val\", char_to_idx, transform=transform, max_length=30)\n",
    "test_dataset = OCRDataset(\"ocr_dataset/test\", char_to_idx, transform=transform, max_length=30)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G1ZYuupIK2ck"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../models/RNN')))\n",
    "from crnn import OCRModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "iCPjthdBK5al"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class OCRModel(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_dim=256):\n",
    "        super(OCRModel, self).__init__()\n",
    "        # CNN Encoder\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # RNN Decoder\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=64 * (256 // 4),  # Feature vector size from CNN\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through CNN\n",
    "        batch_size = x.size(0)\n",
    "        features = self.cnn(x)  # Output shape: [B, 64, H/4, W/4]\n",
    "        features = features.permute(0, 2, 3, 1)  # Shape: [B, H/4, W/4, 64]\n",
    "        features = features.reshape(batch_size, -1, 64 * (256 // 4))  # Shape: [B, Seq_len, Feature_dim]\n",
    "\n",
    "        # Pass through RNN\n",
    "        rnn_out, _ = self.rnn(features)  # Shape: [B, Seq_len, Hidden_dim]\n",
    "        output = self.fc(rnn_out)  # Shape: [B, Seq_len, Num_classes]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0mazKRTK9ak",
    "outputId": "1b6bcb46-0273-472b-fb79-c1abb5974171"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCRModel(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (rnn): GRU(4096, 256, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model, loss, optimizer\n",
    "# Update model to match new vocabulary size\n",
    "model = OCRModel(num_classes=len(char_to_idx))\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)  # Ignore padding tokens if applicable\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gp4IEu4GLPo0",
    "outputId": "cbcafca2-b27b-4f59-fdde-7ed82fe5ff04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/10\n",
      "Train Loss: 2.6928\n",
      "Val Loss: 2.5491\n",
      "Character Accuracy: 0.1288\n",
      "\n",
      "Example 1:\n",
      "True: cyanopia\n",
      "Pred: serriiiaieeyssss\n",
      "\n",
      "Example 2:\n",
      "True: multipresent\n",
      "Pred: serriiiiiiiaannn\n",
      "\n",
      "Example 3:\n",
      "True: Epitoniidae\n",
      "Pred: serriiiaeeesssss\n",
      "--------------------------------------------------\n",
      "Epoch 2/10\n",
      "Train Loss: 2.3426\n",
      "Val Loss: 2.1392\n",
      "Character Accuracy: 0.2005\n",
      "--------------------------------------------------\n",
      "Epoch 3/10\n",
      "Train Loss: 1.9968\n",
      "Val Loss: 1.9147\n",
      "Character Accuracy: 0.2432\n",
      "\n",
      "Example 1:\n",
      "True: cyanopia\n",
      "Pred: periioiaatyyyyyy\n",
      "\n",
      "Example 2:\n",
      "True: multipresent\n",
      "Pred: periiooeeeetttts\n",
      "\n",
      "Example 3:\n",
      "True: Epitoniidae\n",
      "Pred: periioiidaeessss\n",
      "--------------------------------------------------\n",
      "Epoch 4/10\n",
      "Train Loss: 1.8036\n",
      "Val Loss: 1.7283\n",
      "Character Accuracy: 0.2755\n",
      "--------------------------------------------------\n",
      "Epoch 5/10\n",
      "Train Loss: 1.6865\n",
      "Val Loss: 1.6887\n",
      "Character Accuracy: 0.2889\n",
      "\n",
      "Example 1:\n",
      "True: cyanopia\n",
      "Pred: pereietatyysssss\n",
      "\n",
      "Example 2:\n",
      "True: multipresent\n",
      "Pred: pereieossentttys\n",
      "\n",
      "Example 3:\n",
      "True: Epitoniidae\n",
      "Pred: pereieiidaeessss\n",
      "--------------------------------------------------\n",
      "Epoch 6/10\n",
      "Train Loss: 1.6137\n",
      "Val Loss: 1.6489\n",
      "Character Accuracy: 0.2981\n",
      "--------------------------------------------------\n",
      "Epoch 7/10\n",
      "Train Loss: 1.5697\n",
      "Val Loss: 1.6122\n",
      "Character Accuracy: 0.3092\n",
      "\n",
      "Example 1:\n",
      "True: cyanopia\n",
      "Pred: peneeeiaryyyysss\n",
      "\n",
      "Example 2:\n",
      "True: multipresent\n",
      "Pred: peneeeossenttyyy\n",
      "\n",
      "Example 3:\n",
      "True: Epitoniidae\n",
      "Pred: peneeeiidaeessss\n",
      "--------------------------------------------------\n",
      "Epoch 8/10\n",
      "Train Loss: 1.5314\n",
      "Val Loss: 1.5479\n",
      "Character Accuracy: 0.3191\n",
      "--------------------------------------------------\n",
      "Epoch 9/10\n",
      "Train Loss: 1.4999\n",
      "Val Loss: 1.5577\n",
      "Character Accuracy: 0.3200\n",
      "\n",
      "Example 1:\n",
      "True: cyanopia\n",
      "Pred: sereoiiaayyyyysy\n",
      "\n",
      "Example 2:\n",
      "True: multipresent\n",
      "Pred: sereoiessentttty\n",
      "\n",
      "Example 3:\n",
      "True: Epitoniidae\n",
      "Pred: sereoiiidaeessss\n",
      "--------------------------------------------------\n",
      "Epoch 10/10\n",
      "Train Loss: 1.4802\n",
      "Val Loss: 1.5106\n",
      "Character Accuracy: 0.3275\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)  # [batch_size, channels, height, width]\n",
    "        labels = labels.to(device)  # [batch_size, max_length]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)  # [batch_size, seq_len, num_classes]\n",
    "\n",
    "        # Get the actual batch size and sequence length\n",
    "        batch_size, seq_len, num_classes = outputs.shape\n",
    "\n",
    "        # Ensure labels match the sequence length of outputs\n",
    "        labels = labels[:, :seq_len]\n",
    "\n",
    "        # Calculate loss (keep batch dimension)\n",
    "        loss = 0\n",
    "        for i in range(seq_len):\n",
    "            # Get predictions and labels for current position\n",
    "            curr_output = outputs[:, i, :]  # [batch_size, num_classes]\n",
    "            curr_labels = labels[:, i]      # [batch_size]\n",
    "\n",
    "            # Only calculate loss for non-padding positions\n",
    "            mask = curr_labels != -1\n",
    "            if mask.any():\n",
    "                curr_loss = criterion(curr_output[mask], curr_labels[mask])\n",
    "                loss += curr_loss\n",
    "\n",
    "        loss = loss / seq_len  # Average over sequence length\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)  # [batch_size, seq_len, num_classes]\n",
    "\n",
    "            # Get the actual batch size and sequence length\n",
    "            batch_size, seq_len, num_classes = outputs.shape\n",
    "\n",
    "            # Ensure labels match the sequence length of outputs\n",
    "            labels = labels[:, :seq_len]\n",
    "\n",
    "            # Calculate accuracy and loss\n",
    "            for i in range(seq_len):\n",
    "                curr_output = outputs[:, i, :]  # [batch_size, num_classes]\n",
    "                curr_labels = labels[:, i]      # [batch_size]\n",
    "\n",
    "                # Only consider non-padding positions\n",
    "                mask = curr_labels != -1\n",
    "                if mask.any():\n",
    "                    curr_loss = criterion(curr_output[mask], curr_labels[mask])\n",
    "                    total_loss += curr_loss.item()\n",
    "\n",
    "                    predictions = curr_output[mask].argmax(dim=1)\n",
    "                    correct_chars += (predictions == curr_labels[mask]).sum().item()\n",
    "                    total_chars += mask.sum().item()\n",
    "\n",
    "    avg_loss = total_loss / (len(val_loader) * seq_len)\n",
    "    accuracy = correct_chars / total_chars if total_chars > 0 else 0\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def decode_prediction(prediction, idx_to_char):\n",
    "    \"\"\"Convert a prediction tensor to a string\"\"\"\n",
    "    return ''.join(idx_to_char[idx.item()] for idx in prediction if idx != -1 and idx.item() < len(idx_to_char))\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "    # Validate\n",
    "    val_loss, accuracy = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Character Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Print examples every few epochs\n",
    "    if epoch % 2 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            images, labels = next(iter(val_loader))\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            predictions = outputs.argmax(dim=2)\n",
    "\n",
    "            # Print a few examples\n",
    "            for i in range(min(3, len(images))):\n",
    "                true_text = decode_prediction(labels[i], idx_to_char)\n",
    "                pred_text = decode_prediction(predictions[i].cpu(), idx_to_char)\n",
    "                print(f\"\\nExample {i+1}:\")\n",
    "                print(f\"True: {true_text}\")\n",
    "                print(f\"Pred: {pred_text}\")\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Fcb33y4bf4g",
    "outputId": "a8ee3644-4d71-4682-b5ed-7bff524cb31e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting final evaluation...\n",
      "\n",
      "Evaluating trained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:13<00:00, 22.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained Model Results:\n",
      "Character Accuracy: 33.03%\n",
      "Word Accuracy (Exact Match): 0.00%\n",
      "\n",
      "Example Predictions:\n",
      "\n",
      "Example 1:\n",
      "True: superabundance\n",
      "Pred: sereeedandaneess\n",
      "Character Accuracy: 50.00%\n",
      "\n",
      "Example 2:\n",
      "True: presbytic\n",
      "Pred: sereeeticsssssss\n",
      "Character Accuracy: 33.33%\n",
      "\n",
      "Example 3:\n",
      "True: sewn\n",
      "Pred: sereeeeeyyssyyyw\n",
      "Character Accuracy: 50.00%\n",
      "\n",
      "Example 4:\n",
      "True: acoelomatous\n",
      "Pred: sereeeiatousssss\n",
      "Character Accuracy: 50.00%\n",
      "\n",
      "Example 5:\n",
      "True: afforestable\n",
      "Pred: sereeeaaableesss\n",
      "Character Accuracy: 41.67%\n",
      "\n",
      "Example 6:\n",
      "True: greener\n",
      "Pred: sereeeeyyyyyQJqq\n",
      "Character Accuracy: 28.57%\n",
      "\n",
      "Example 7:\n",
      "True: aleph\n",
      "Pred: sereeeeyyysy6qqq\n",
      "Character Accuracy: 0.00%\n",
      "\n",
      "Example 8:\n",
      "True: Saturnicentric\n",
      "Pred: sereeeteentticcc\n",
      "Character Accuracy: 35.71%\n",
      "\n",
      "Example 9:\n",
      "True: condescendingnes\n",
      "Pred: sereeeldddignnes\n",
      "Character Accuracy: 37.50%\n",
      "\n",
      "Example 10:\n",
      "True: unsubstituted\n",
      "Pred: sereeetttttedddr\n",
      "Character Accuracy: 38.46%\n",
      "\n",
      "Example 11:\n",
      "True: antimonarchial\n",
      "Pred: sereeeorcchially\n",
      "Character Accuracy: 35.71%\n",
      "\n",
      "Example 12:\n",
      "True: lucullite\n",
      "Pred: sereeeitessssssw\n",
      "Character Accuracy: 33.33%\n",
      "\n",
      "Example 13:\n",
      "True: scribbled\n",
      "Pred: sereeeeedyyyssss\n",
      "Character Accuracy: 44.44%\n",
      "\n",
      "Example 14:\n",
      "True: maritage\n",
      "Pred: sereeeeessyyQJqq\n",
      "Character Accuracy: 25.00%\n",
      "\n",
      "Example 15:\n",
      "True: polyglottism\n",
      "Pred: sereeetttismmnms\n",
      "Character Accuracy: 41.67%\n",
      "\n",
      "Example 16:\n",
      "True: gonystylaceous\n",
      "Pred: sereeeeaaceousss\n",
      "Character Accuracy: 42.86%\n",
      "\n",
      "Example 17:\n",
      "True: abilo\n",
      "Pred: sereeeeyssssss6q\n",
      "Character Accuracy: 0.00%\n",
      "\n",
      "Example 18:\n",
      "True: chylemia\n",
      "Pred: sereeeoayyyyssss\n",
      "Character Accuracy: 25.00%\n",
      "\n",
      "Example 19:\n",
      "True: outblunder\n",
      "Pred: sereeeederysssss\n",
      "Character Accuracy: 30.00%\n",
      "\n",
      "Example 20:\n",
      "True: provaccinist\n",
      "Pred: sereeetinistttss\n",
      "Character Accuracy: 41.67%\n",
      "\n",
      "Example 21:\n",
      "True: Nototherium\n",
      "Pred: sereeearrummmmrx\n",
      "Character Accuracy: 27.27%\n",
      "\n",
      "Example 22:\n",
      "True: unlogged\n",
      "Pred: sereeeoddyyyyyss\n",
      "Character Accuracy: 12.50%\n",
      "\n",
      "Example 23:\n",
      "True: Tomistoma\n",
      "Pred: sereeeimaayyssss\n",
      "Character Accuracy: 22.22%\n",
      "\n",
      "Example 24:\n",
      "True: orthosubstituted\n",
      "Pred: sereeeisiittcied\n",
      "Character Accuracy: 18.75%\n",
      "\n",
      "Example 25:\n",
      "True: thereabove\n",
      "Pred: sereeeeoreesssss\n",
      "Character Accuracy: 30.00%\n",
      "\n",
      "Example 26:\n",
      "True: insomnia\n",
      "Pred: sereeeaayyysssss\n",
      "Character Accuracy: 12.50%\n",
      "\n",
      "Example 27:\n",
      "True: reparably\n",
      "Pred: sereeellyyyyssss\n",
      "Character Accuracy: 33.33%\n",
      "\n",
      "Example 28:\n",
      "True: taratantarize\n",
      "Pred: sereeeiaaiizeess\n",
      "Character Accuracy: 38.46%\n",
      "\n",
      "Example 29:\n",
      "True: bowlful\n",
      "Pred: sereeellyyyyyswq\n",
      "Character Accuracy: 14.29%\n",
      "\n",
      "Example 30:\n",
      "True: transversion\n",
      "Pred: sereeeessionnnnn\n",
      "Character Accuracy: 41.67%\n",
      "\n",
      "Example 31:\n",
      "True: coenogamete\n",
      "Pred: sereeeemteeessss\n",
      "Character Accuracy: 18.18%\n",
      "\n",
      "Example 32:\n",
      "True: onomatopoesis\n",
      "Pred: sereeeeoeesissss\n",
      "Character Accuracy: 30.77%\n",
      "\n",
      "Analyzing training data for baseline predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2497/2497 [01:31<00:00, 27.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating baseline model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 26.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Model Results:\n",
      "Character Accuracy: 8.81%\n",
      "Word Accuracy (Exact Match): 0.00%\n",
      "\n",
      "Example Predictions:\n",
      "\n",
      "Example 1:\n",
      "True: superabundance\n",
      "Pred: sereeiieee\n",
      "Character Accuracy: 14.29%\n",
      "\n",
      "Example 2:\n",
      "True: presbytic\n",
      "Pred: sereeiieee\n",
      "Character Accuracy: 0.00%\n",
      "\n",
      "Example 3:\n",
      "True: sewn\n",
      "Pred: sereeiieee\n",
      "Character Accuracy: 20.00%\n",
      "\n",
      "Example 4:\n",
      "True: acoelomatous\n",
      "Pred: sereeiieee\n",
      "Character Accuracy: 8.33%\n",
      "\n",
      "Example 5:\n",
      "True: afforestable\n",
      "Pred: sereeiieee\n",
      "Character Accuracy: 0.00%\n",
      "\n",
      "Final Comparison:\n",
      "--------------------------------------------------\n",
      "Metric                      Trained Model        Baseline\n",
      "--------------------------------------------------\n",
      "Character Accuracy                 33.03%           8.81%\n",
      "Word Accuracy                       0.00%           0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, test_loader, idx_to_char, device, num_examples=5):\n",
    "    model.eval()\n",
    "    total_chars = 0\n",
    "    correct_chars = 0\n",
    "    total_words = 0\n",
    "    correct_words = 0\n",
    "    examples = []\n",
    "\n",
    "    print(\"\\nEvaluating trained model...\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)  # [batch_size, seq_len, num_classes]\n",
    "            batch_size, seq_len, num_classes = outputs.shape\n",
    "\n",
    "            # Ensure labels match the sequence length of outputs\n",
    "            labels = labels[:, :seq_len]\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = outputs.argmax(dim=2)  # [batch_size, seq_len]\n",
    "\n",
    "            # Calculate accuracy\n",
    "            for i in range(seq_len):\n",
    "                curr_preds = predictions[:, i]\n",
    "                curr_labels = labels[:, i]\n",
    "\n",
    "                # Only consider non-padding positions\n",
    "                mask = curr_labels != -1\n",
    "                if mask.any():\n",
    "                    correct_chars += (curr_preds[mask] == curr_labels[mask]).sum().item()\n",
    "                    total_chars += mask.sum().item()\n",
    "\n",
    "            # Collect examples\n",
    "            if len(examples) < num_examples:\n",
    "                for i in range(len(images)):\n",
    "                    true_text = decode_prediction(labels[i], idx_to_char)\n",
    "                    pred_text = decode_prediction(predictions[i].cpu(), idx_to_char)\n",
    "\n",
    "                    # Calculate per-example accuracy\n",
    "                    example_correct = 0\n",
    "                    example_total = 0\n",
    "                    for j in range(len(true_text)):\n",
    "                        if j < len(pred_text):\n",
    "                            if true_text[j] == pred_text[j]:\n",
    "                                example_correct += 1\n",
    "                        example_total += 1\n",
    "\n",
    "                    example_accuracy = example_correct / example_total if example_total > 0 else 0\n",
    "                    examples.append((true_text, pred_text, example_accuracy))\n",
    "\n",
    "                    # Word accuracy\n",
    "                    if true_text == pred_text:\n",
    "                        correct_words += 1\n",
    "                    total_words += 1\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    char_accuracy = (correct_chars / total_chars * 100) if total_chars > 0 else 0\n",
    "    word_accuracy = (correct_words / total_words * 100) if total_words > 0 else 0\n",
    "\n",
    "    print(\"\\nTrained Model Results:\")\n",
    "    print(f\"Character Accuracy: {char_accuracy:.2f}%\")\n",
    "    print(f\"Word Accuracy (Exact Match): {word_accuracy:.2f}%\")\n",
    "\n",
    "    print(\"\\nExample Predictions:\")\n",
    "    for i, (true_text, pred_text, char_acc) in enumerate(examples, 1):\n",
    "        print(f\"\\nExample {i}:\")\n",
    "        print(f\"True: {true_text}\")\n",
    "        print(f\"Pred: {pred_text}\")\n",
    "        print(f\"Character Accuracy: {char_acc*100:.2f}%\")\n",
    "\n",
    "    return char_accuracy, word_accuracy\n",
    "\n",
    "class BaselinePredictor:\n",
    "    def __init__(self, train_loader):\n",
    "        \"\"\"Initialize baseline predictor with training data statistics\"\"\"\n",
    "        print(\"\\nAnalyzing training data for baseline predictions...\")\n",
    "        self.char_freqs = {}  # Character frequency at each position\n",
    "        self.avg_length = 0\n",
    "        self.total_samples = 0\n",
    "\n",
    "        # Collect statistics from training data\n",
    "        for _, labels in tqdm(train_loader):\n",
    "            self.total_samples += len(labels)\n",
    "            for label_tensor in labels:\n",
    "                text = decode_prediction(label_tensor, idx_to_char)\n",
    "                self.avg_length += len(text)\n",
    "\n",
    "                # Count character frequencies at each position\n",
    "                for pos, char in enumerate(text):\n",
    "                    if pos not in self.char_freqs:\n",
    "                        self.char_freqs[pos] = {}\n",
    "                    self.char_freqs[pos][char] = self.char_freqs[pos].get(char, 0) + 1\n",
    "\n",
    "        self.avg_length = round(self.avg_length / self.total_samples)\n",
    "\n",
    "        # Convert frequencies to most common characters\n",
    "        self.most_common_chars = {}\n",
    "        for pos in self.char_freqs:\n",
    "            self.most_common_chars[pos] = max(self.char_freqs[pos].items(), key=lambda x: x[1])[0]\n",
    "\n",
    "    def predict(self, batch_size):\n",
    "        \"\"\"Generate predictions for a batch\"\"\"\n",
    "        predictions = []\n",
    "        for _ in range(batch_size):\n",
    "            pred = ''\n",
    "            for pos in range(min(self.avg_length, max(self.char_freqs.keys()) + 1)):\n",
    "                pred += self.most_common_chars.get(pos, 'a')  # Default to 'a' if position not seen\n",
    "            predictions.append(pred)\n",
    "        return predictions\n",
    "\n",
    "def evaluate_baseline(baseline_predictor, test_loader, num_examples=5):\n",
    "    print(\"\\nEvaluating baseline model...\")\n",
    "    total_chars = 0\n",
    "    correct_chars = 0\n",
    "    total_words = 0\n",
    "    correct_words = 0\n",
    "    examples = []\n",
    "\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        batch_predictions = baseline_predictor.predict(len(images))\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            true_text = decode_prediction(labels[i], idx_to_char)\n",
    "            pred_text = batch_predictions[i]\n",
    "\n",
    "            # Calculate character accuracy\n",
    "            min_len = min(len(true_text), len(pred_text))\n",
    "            max_len = max(len(true_text), len(pred_text))\n",
    "\n",
    "            correct = sum(1 for j in range(min_len) if true_text[j] == pred_text[j])\n",
    "            correct_chars += correct\n",
    "            total_chars += max_len\n",
    "\n",
    "            # Word accuracy\n",
    "            if true_text == pred_text:\n",
    "                correct_words += 1\n",
    "            total_words += 1\n",
    "\n",
    "            # Store example\n",
    "            if len(examples) < num_examples:\n",
    "                example_accuracy = correct / max_len if max_len > 0 else 0\n",
    "                examples.append((true_text, pred_text, example_accuracy))\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    char_accuracy = (correct_chars / total_chars * 100) if total_chars > 0 else 0\n",
    "    word_accuracy = (correct_words / total_words * 100) if total_words > 0 else 0\n",
    "\n",
    "    print(\"\\nBaseline Model Results:\")\n",
    "    print(f\"Character Accuracy: {char_accuracy:.2f}%\")\n",
    "    print(f\"Word Accuracy (Exact Match): {word_accuracy:.2f}%\")\n",
    "\n",
    "    print(\"\\nExample Predictions:\")\n",
    "    for i, (true_text, pred_text, char_acc) in enumerate(examples, 1):\n",
    "        print(f\"\\nExample {i}:\")\n",
    "        print(f\"True: {true_text}\")\n",
    "        print(f\"Pred: {pred_text}\")\n",
    "        print(f\"Character Accuracy: {char_acc*100:.2f}%\")\n",
    "\n",
    "    return char_accuracy, word_accuracy\n",
    "\n",
    "# Run evaluations\n",
    "print(\"Starting final evaluation...\")\n",
    "\n",
    "# Evaluate trained model\n",
    "model_char_acc, model_word_acc = evaluate_model(\n",
    "    model, test_loader, idx_to_char, device, num_examples=5\n",
    ")\n",
    "\n",
    "# Create and evaluate baseline\n",
    "baseline_predictor = BaselinePredictor(train_loader)\n",
    "baseline_char_acc, baseline_word_acc = evaluate_baseline(\n",
    "    baseline_predictor, test_loader, num_examples=5\n",
    ")\n",
    "\n",
    "# Print comparison\n",
    "print(\"\\nFinal Comparison:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Metric':<25} {'Trained Model':>15} {'Baseline':>15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Character Accuracy':<25} {model_char_acc:>14.2f}% {baseline_char_acc:>14.2f}%\")\n",
    "print(f\"{'Word Accuracy':<25} {model_word_acc:>14.2f}% {baseline_word_acc:>14.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
